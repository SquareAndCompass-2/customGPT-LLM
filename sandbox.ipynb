{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tiktoken\n",
    "import PyPDF2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class utilities:\n",
    "    def __init__(self) -> None:\n",
    "        self.enc = self.initialize_encoder()\n",
    "\n",
    "    \n",
    "    def initialize_encoder(self):\n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        return enc\n",
    "\n",
    "    \n",
    "    def print(self, string:str, new_line=True):\n",
    "        if new_line:\n",
    "            string = string + \"\\n\"\n",
    "        sys.stdout.write(string)\n",
    "    \n",
    "    \n",
    "    def print_filler(self, myString:str, filler_char='#'):\n",
    "        total_len = len(myString)\n",
    "        filler = []\n",
    "        for i in range(total_len):\n",
    "            filler.append(filler_char)\n",
    "        filler = ''.join(filler)\n",
    "        self.print(filler)\n",
    "\n",
    "    \n",
    "    def read_pdf(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            content = ''\n",
    "            \n",
    "            for i in range(num_pages):\n",
    "                page = pdf_reader.pages[i]\n",
    "                content += page.extract_text()\n",
    "        \n",
    "        return content.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, idx, target):\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customGPT_trainer(BigramLanguageModel, utilities):\n",
    "    def __init__(self, path) -> None:\n",
    "        '''\n",
    "        METADATA\n",
    "        self.enc -> self.__init__()\n",
    "        self.original_data -> self.load_data()\n",
    "        self.data -> self.load_data()\n",
    "        self.vocab_size -> self.load_data()\n",
    "        '''\n",
    "        self.enc = tiktoken.get_encoding(\"gpt2\")\n",
    "        self.load_data(path)\n",
    "        super().__init__(vocab_size=self.vocab_size)\n",
    "\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        encoded = self.enc.encode(data)\n",
    "        return encoded\n",
    "    \n",
    "\n",
    "    def decode_data(self, encoded_data):\n",
    "        decoded = self.enc.decode(encoded_data)\n",
    "        return decoded\n",
    "    \n",
    "    \n",
    "    def load_data(self, path:str):\n",
    "        if '.pdf' in path:\n",
    "            data = self.read_pdf(path)\n",
    "        else:\n",
    "            data = \"\"\n",
    "        \n",
    "        # Load Original Data\n",
    "        self.original_data = data\n",
    "\n",
    "        # Create token embedding table\n",
    "        chars = sorted(set(self.original_data))\n",
    "        self.vocab_size = len(chars)\n",
    "        \n",
    "        # Encode data\n",
    "        data = self.enc.encode(data)\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    def split_data_train_val(self, thresh=0.9):\n",
    "        n = int(thresh*len(self.data))\n",
    "        self.train_data = self.data[:n]\n",
    "        self.val_data = self.data[n:]\n",
    "\n",
    "\n",
    "    def generate_batches(self, split:str, batch_size:int=4, block_size:int=8):\n",
    "        data = self.train_data if split == 'train' else self.val_data\n",
    "        ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "        x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String:  Program Support Center DEPARTMENT OF HEALTH & HUMAN SERVICES Financial Management Portfolio  Cost Allocation Services 101 9th Street, Suite 4-600 San Francisco, CA 94103-6705 PHONE: (516) 548-8931 EMAIL: CAS-SF@psc.hhs.gov   Memorandum DATE: March 23, 2023 TO: Mary Mitchell, Chief Program Support Center, Debt Collection Center SUBJECT: Account Receivable Based on CAS’ Review of the State of California Pension Refund Proposal ORGANIZATION: State of California  415 L Street, 10th Floor  Sacramento, CA 95814  EIN:52-0395286 I. The following document related to the above review is attached: CAS determination letter dated March 23, 2023  II. Recovery of the disallowance will be accomplished via: Cash $3,996,109.58  Total Disallowance $3,996,109.58  III. Appeals: The grantee does not plan to appeal. If you have any questions, please contact our office at (516) 437-8931. Sincerely, John Doe, Director  Cost Allocation Services Attachment \n",
      "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "Encoded String: tensor([ 6118,  7929,  3337,  5550, 30709, 10979,  3963, 11179, 40818,  1222,\n",
      "        45850,  1565, 49254, 11302,  8549,  4347, 13652,   220,  6446,  1439,\n",
      "         5040,  6168,  8949,   860,   400,  3530,    11, 26264,   604,    12,\n",
      "         8054,  2986,  6033,    11,  7257, 10048, 15197,    12,    21, 34801,\n",
      "         9370, 11651,    25,   357, 47493,     8,   642,  2780,    12,  4531,\n",
      "         3132,   412,  5673,  4146,    25, 35106,    12, 20802,    31, 27566,\n",
      "           13,    71, 11994,    13,  9567,   220,   220, 41157, 25933,   360,\n",
      "         6158,    25,  2805,  2242,    11,  1160,  1954,  5390,    25,  5335,\n",
      "        14526,    11,  5953,  6118,  7929,  3337,    11, 30319, 12251,  3337,\n",
      "        28932, 23680,    25, 10781, 19520, 21911, 13403,   319, 35106,   447,\n",
      "          247,  6602,   286,   262,  1812,   286,  3442, 46391,  6524,   917,\n",
      "         1041, 40007,  6375, 45028, 14887,  6234,    25,  1812,   286,  3442,\n",
      "          220, 40643,   406,  3530,    11,   838,   400, 22343,   220, 19375,\n",
      "           11,  7257,   860,  3365,  1415,   220,   412,  1268,    25,  4309,\n",
      "           12,    15, 31010, 27033,   314,    13,   383,  1708,  3188,  3519,\n",
      "          284,   262,  2029,  2423,   318,  7223,    25, 35106, 12123,  3850,\n",
      "        14567,  2805,  2242,    11,  1160,  1954,   220,  2873,    13, 21007,\n",
      "          286,   262,   595, 12154,   590,   481,   307, 13013,  2884,    25,\n",
      "        16210,   720,    18,    11, 38565,    11, 14454,    13,  3365,   220,\n",
      "         7472,  3167, 12154,   590,   720,    18,    11, 38565,    11, 14454,\n",
      "           13,  3365,   220,  6711,    13, 20172,    25,   383,  7264,  1453,\n",
      "          857,   407,  1410,   284,  5198,    13,  1002,   345,   423,   597,\n",
      "         2683,    11,  3387,  2800,   674,  2607,   379,   357, 47493,     8,\n",
      "          604,  2718,    12,  4531,  3132,    13,  4619, 38015,    11,  1757,\n",
      "        31780,    11,  5890,   220,  6446,  1439,  5040,  6168,  3460, 15520,\n",
      "          220])\n",
      "Decoded String:  Program Support Center DEPARTMENT OF HEALTH & HUMAN SERVICES Financial Management Portfolio  Cost Allocation Services 101 9th Street, Suite 4-600 San Francisco, CA 94103-6705 PHONE: (516) 548-8931 EMAIL: CAS-SF@psc.hhs.gov   Memorandum DATE: March 23, 2023 TO: Mary Mitchell, Chief Program Support Center, Debt Collection Center SUBJECT: Account Receivable Based on CAS’ Review of the State of California Pension Refund Proposal ORGANIZATION: State of California  415 L Street, 10th Floor  Sacramento, CA 95814  EIN:52-0395286 I. The following document related to the above review is attached: CAS determination letter dated March 23, 2023  II. Recovery of the disallowance will be accomplished via: Cash $3,996,109.58  Total Disallowance $3,996,109.58  III. Appeals: The grantee does not plan to appeal. If you have any questions, please contact our office at (516) 437-8931. Sincerely, John Doe, Director  Cost Allocation Services Attachment \n"
     ]
    }
   ],
   "source": [
    "myGPT = customGPT_trainer('data/CAS.pdf')\n",
    "\n",
    "myGPT.print(\"Original String: \" + str(myGPT.original_data))\n",
    "myGPT.print_filler(\"Original String: \"+ str(myGPT.original_data), filler_char='*')\n",
    "myGPT.print(\"Encoded String: \" + str(myGPT.data))\n",
    "myGPT.print(\"Decoded String: \" + str(myGPT.enc.decode(myGPT.data.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGPT.split_data_train_val(thresh=1)\n",
    "xb, yb = myGPT.generate_batches(split='train', batch_size=8, block_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION BLOCK\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "for b in range(batch_size):     # Batch Dimension\n",
    "    for t in range(block_size): # Time Dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "    print(f\"when input is \\\"{myGPT.enc.decode(context.tolist())}\\\" the target is {myGPT.enc.decode([target.tolist()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
